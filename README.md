# A ML based approach for bias correction of microwave radiances in Regional NWP

## Collaborators: 

Alice Abramowicz, Isabel Monteiro, Kirien Whan, Irene Garcia Marti & Sanne Willems.

## Project description:

HARMONIE-AROME is a regional Numerical Weather Prediction (NWP) model used for short- range weather forecasting in several operational centres across Europe. Microwave radiance observations from satellites are one of the main contributors to its forecast skill, but these observations contain biases that need to be corrected. Currently, in HARMONIE-AROME, bias correction is performed using a Variational Bias Correction method (VarBC), which consists of linear models including different bias predictors alongside their bias coefficients. However, this method is computationally intensive. This study investigates the potential of machine learning models to emulate the VarBC method by predicting the bias coefficients of its linear equations, offering a more computationally efficient alternative. This research uses data corresponding to the microwave radiance observations from the instruments AMSU-A, MHS and MWHS2. The Machine Learning (ML) models were trained on data from the DINI domain and subsequently tested on the Dutch domain. The findings reveal that the ML models successfully emulate VarBC on a new, unseen domain and that they can be trained within seconds/minutes. Moreover, the predictions generated by these models are immediately usable without requiring a spin-up phase. The study further reveals that including bias predictors additional to those preselected by HARMONIE-AROME does not enhance the prediction accuracy. Furthermore, the research suggests that data from some instruments are helpful in predicting bias coefficients from other instruments. 

## Table of Contents:
1. data Engineering
    1. ODB preparation
    2. VarBC preparation
    3. Create full datasets
2. Datasets
3. Data exploration
    1. data distributions
    2. data correlations
    3. VarBC coefficients evolution over time in the Dutch domain
4. ML models fitting
    1. Neural Networks (NN)
    2. Adaptive Boosting (AB)
    3. Random Forest (RF)
        1. Sensitivity analysis on bias predictors
        2. Sensitivity analysis on sensors
    4. Quantile Random Forest (QRF)

## Practical information: how to run the project

To run the data engineering section yourself, you need access to data from HARMONIE-AROME. More specifically, you need access to the CCMA and VarBC.cycles files. Alternatively, you can skip the data engineering section and directly use the datasets available in Section 2 (*Datasets*).

## Data Engineering

To create the datasets, follow these steps.

**PS**: we create the Dutch and DINI domains in parallel, therefore each step often contains 2 scripts: one script for the Dutch, and one script for the DINI domain.

1. ODB preparation

    1. `get_odbstuff_2023_DINI.sh`, `get_odbstuff_2021_Dutch.sh`

        Copy, for the year-month-day-cycle (i.e., $yy$mm$dd$cy) of interest, the `odb_stuff.tar` from `HARMONIE 4DVar`. Keep only the `odb_ccma.tar` and `VARBC.cycle` files, and rename them based on their corresponding $yy$mm$dd$cy.

    2. `untar_2021_dutch.sh`, `untar_2023_dini.sh`
    
        take as input the odb_ccma$yy$mm$dd$cy.tar files from `get_odbstuff_2021_Dutch.sh`, `get_odbstuff_2023_DINI.sh`; untar these odb_ccma files; reorganize them in directories based on their $yy$mm$dd$cy inside new directories named ​​ccma_dutch_2021, ccma_dini_2023 

        **PS**: change the EXP and output_dir according to your needs

    3. `WriteODBreq_V1_2021.sh`, `WriteODBreq_V1_2023.sh`

        From the CCMA files organized in directories based on their $yy$mm$dd$cy, make an SQL request to fetch the variables:
        - first-guess departures
        - analysis departures
        - bias-corrected first guess
        - observation values
        Store the results in loop_DUTCH_ALL_"$yy$mm$dd$cy".txt

        **PS**: change the HM_DIR as well as the other variables at the start of the document according to your needs.

2. VarBC preparation

    1. `makeDirectories_varbc2021.sh`, `makeDirectories_varbc2023.sh`

        take as inputs the VarBC.cycle files obtained from the ODB preparation and reorganize them into directories based on $yy$mm$dd$cy inside a new folder named VarBC_2021, VarBC_2023. 

    2. `varbc_dataset_preparation.py`

        Use the reorganized VarBC cycles as inputs -i, create an output directory -o, and gather the VarBC cycles into a unified dataframe. Obtain `varbc_dataset_dutch_all_sat_sen.csv`, `varbc_dataset_dini_all_sat_sen.csv` as outputs.

3. Create full datasets

    1. `arrange_loop_datasets.py`
    
        Modify loop_DUTCH_ALL and loop_DINI_ALL files to make sure that they are formatted in csv and that we only keep the satellites and sensors which are in both the Dutch and the Dini domain. Change the file names such that they end with “_common.csv” for the common satellites and sensors accross the two domains.
        **PS**: change directory according to your needs

    2. `arrange_varbc_dataset.py`

        remove unnecessary rows and columns from `varbc_dataset_dutch_all_sat_sen.csv`, `varbc_dataset_dini_all_sat_sen.csv` and obtain `varbc_dataset_dutch_common_sat_sen.csv`, `varbc_dataset_dini_common_sat_sen.csv`

    3. `JoinLoopVarbc.py`

        Read the VarBC dataframe from your input -i and the CCMA files from -c; 
        Compute statistics from:
        - first-guess departures 
        - analysis departures
        - bias-corrected first guess
        - observation values
        in the CCMA files;
        Match the rows from VarBC and CCMA files based on their ['time', 'sat', 'sensor', 'channel'];
        Create `big_df_stats_2021.csv` and `big_df_stats_2023.csv`

    4. `create_X_train_test.py`

        From `big_df_stats_2021.csv`, `big_df_stats_2023.csv`:
        - Fill in the missing values with 0 (i.e., for the covariances of non-existent predictors);
        - Take care of categorical and numerical variables;
        - Design new features;
        - Scale variables;
        - Create the finale X_train, y_train, X_test, y_test (as well as their scaled counterparts).



